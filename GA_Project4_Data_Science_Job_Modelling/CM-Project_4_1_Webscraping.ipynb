{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Part 1: Web scraping\n",
    "\n",
    "## [1.1 Import packages](#1.1)\n",
    "\n",
    "## [1.2 Scrape data from indeed.com](#1.2)\n",
    "\n",
    "## [1.3 Create dataframe and export](#1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.1'>1.1 Import packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.2'>1.2 Scrape data from indeed.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize lists to store relevant features\n",
    "titles = []\n",
    "companies = []\n",
    "summaries = []\n",
    "locations = []\n",
    "salary_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data from the first page of results\n",
    "#First get html for search page\n",
    "url = 'https://au.indeed.com/jobs?q=data+scientist&l=Australia'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "#Then make a list of all the urls of the individual job listings\n",
    "link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "urls = []\n",
    "for i in range(len(link)):\n",
    "    urls.append(link[i]['href'])\n",
    "     \n",
    "#Now iterate through this list to scrape relevant information from each page\n",
    "for address in urls:\n",
    "    sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "    response2 = requests.get(sub_url)\n",
    "    html2 = response2.text\n",
    "    soup2 = BeautifulSoup(html2, 'lxml')\n",
    "    title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "    [titles.append(title[i].text) for i in range(len(title))]\n",
    "    for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "        company = x.find('span',{'class':'company'})\n",
    "        [companies.append(company.text)]\n",
    "        loc = x.find('span',{'class':'location'})\n",
    "        [locations.append(loc.text)]    \n",
    "        try:\n",
    "            salary = x.find('span',{'class':'no-wrap'})\n",
    "            [salary_info.append(salary.text)]\n",
    "        except:\n",
    "            salary = 'No info'\n",
    "            [salary_info.append(salary)]\n",
    "    summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "    [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the remaining pages:\n",
    "for i in range(10,540,10):\n",
    "    url = 'https://au.indeed.com/jobs?q=data+scientist&l=Australia&start='+str(i)\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "    urls = []\n",
    "    for i in range(len(link)):\n",
    "        urls.append(link[i]['href'])\n",
    "    for address in urls:\n",
    "        sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "        response2 = requests.get(sub_url)\n",
    "        html2 = response2.text\n",
    "        soup2 = BeautifulSoup(html2, 'lxml')\n",
    "        title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "        [titles.append(title[i].text) for i in range(len(title))]\n",
    "        for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "            company = x.find('span',{'class':'company'})\n",
    "            [companies.append(company.text)]\n",
    "            loc = x.find('span',{'class':'location'})\n",
    "            [locations.append(loc.text)]    \n",
    "            try:\n",
    "                salary = x.find('span',{'class':'no-wrap'})\n",
    "                [salary_info.append(salary.text)]\n",
    "            except:\n",
    "                salary = 'No info'\n",
    "                [salary_info.append(salary)]\n",
    "        summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "        [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat for 'data analyst' jobs\n",
    "url = 'https://au.indeed.com/jobs?q=data+analyst&l=Australia'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "urls = []\n",
    "for i in range(len(link)):\n",
    "    urls.append(link[i]['href'])\n",
    "for address in urls:\n",
    "    sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "    response2 = requests.get(sub_url)\n",
    "    html2 = response2.text\n",
    "    soup2 = BeautifulSoup(html2, 'lxml')\n",
    "    title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "    [titles.append(title[i].text) for i in range(len(title))]\n",
    "    for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "        company = x.find('span',{'class':'company'})\n",
    "        [companies.append(company.text)]\n",
    "        loc = x.find('span',{'class':'location'})\n",
    "        [locations.append(loc.text)]    \n",
    "        try:\n",
    "            salary = x.find('span',{'class':'no-wrap'})\n",
    "            [salary_info.append(salary.text)]\n",
    "        except:\n",
    "            salary = 'No info'\n",
    "            [salary_info.append(salary)]\n",
    "    summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "    [summaries.append(summ[i].text) for i in range(len(summ))]\n",
    "for i in range(10,540,10):\n",
    "    url = 'https://au.indeed.com/jobs?q=data+analyst&l=Australia&start='+str(i)\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "    urls = []\n",
    "    for i in range(len(link)):\n",
    "        urls.append(link[i]['href'])\n",
    "    for address in urls:\n",
    "        sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "        response2 = requests.get(sub_url)\n",
    "        html2 = response2.text\n",
    "        soup2 = BeautifulSoup(html2, 'lxml')\n",
    "        title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "        [titles.append(title[i].text) for i in range(len(title))]\n",
    "        for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "            company = x.find('span',{'class':'company'})\n",
    "            [companies.append(company.text)]\n",
    "            loc = x.find('span',{'class':'location'})\n",
    "            [locations.append(loc.text)]    \n",
    "            try:\n",
    "                salary = x.find('span',{'class':'no-wrap'})\n",
    "                [salary_info.append(salary.text)]\n",
    "            except:\n",
    "                salary = 'No info'\n",
    "                [salary_info.append(salary)]\n",
    "        summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "        [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1.3'>1.3 Create a dataframe and export</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "df = pd.DataFrame({'title':titles,'company':companies,'location':locations,'salary':salary_info,'summary':summaries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Telstra</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Full-time, Permanent</td>\n",
       "      <td>Telstra’s vision is to become a world class te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>No info</td>\n",
       "      <td>The International Institute of Data &amp; Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nearmap - AU</td>\n",
       "      <td>Barangaroo NSW</td>\n",
       "      <td>Full-time, Permanent</td>\n",
       "      <td>Want to do petabyte scale deep learning and sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>nbn™</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>No info</td>\n",
       "      <td>As nbn is moving to the scale phase, in parall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ResMed</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>No info</td>\n",
       "      <td>Why ResMed?\\n\\nImagine what you could accompli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                                      company  \\\n",
       "0                  Data Engineer                                      Telstra   \n",
       "1  Junior Data Analyst/Scientist  International Institute of Data & Analytics   \n",
       "2                 Data Scientist                                 Nearmap - AU   \n",
       "3                 Data Scientist                                         nbn™   \n",
       "4                 Data Scientist                                       ResMed   \n",
       "\n",
       "         location                salary  \\\n",
       "0      Sydney NSW  Full-time, Permanent   \n",
       "1      Sydney NSW               No info   \n",
       "2  Barangaroo NSW  Full-time, Permanent   \n",
       "3      Sydney NSW               No info   \n",
       "4      Sydney NSW               No info   \n",
       "\n",
       "                                             summary  \n",
       "0  Telstra’s vision is to become a world class te...  \n",
       "1  The International Institute of Data & Analytic...  \n",
       "2  Want to do petabyte scale deep learning and sh...  \n",
       "3  As nbn is moving to the scale phase, in parall...  \n",
       "4  Why ResMed?\\n\\nImagine what you could accompli...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export dataframe to csv\n",
    "filepath = 'jobs.csv'\n",
    "df.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
